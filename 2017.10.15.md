![](1.jpg)  

                作者：Roger Parloff   
                贾斯汀·梅茨的插图   
                2016年9月28日下午5:00  
                译者：北京林业大学计算机与网络协会   赵铖博

原网址：http://fortune.com/ai-artificial-intelligence-deep-machine-learning/

---
# 为什么深度学习突然改变你的生活？



在过去四年中，读者无疑注意到广泛日常技术的质量发生了巨大的飞跃。   

最明显的是，智能手机上的语音识别功能比以往更好。 当我们用语音命令来叫我们的配偶时，可以立刻联系到他们。 我们没有与Amtrak或一个愤怒的前任联系。

事实上，无论是亚马逊的Alexa，苹果的Siri，微软的Cortana，还是Google的许多语音应答功能，我们正在与他们交谈，我们正越来越多地与我们的电脑交互。 中国搜索巨头百度表示，客户在过去18个月内使用的语音响应次数翻了三倍。

随着谷歌， 微软，Facebook，和百度每月研发出的新特性，机器翻译和其他形式的语言处理也变得更加令人信服。 Google翻译现在使用将一种语言的口语句子翻译成另一语言的口语的句子，这些句子可以是32个语言中的一种。同时它提供了103种语言的文本翻译，其中包括Cebuano，Igbo和Zulu。 Google的收件箱应用程序可以为许多接收到的的电子邮件提供三种类型的自动回复。

接着是图像识别的进步。 同样的四家公司都有这种功能，这种可以让你搜索或自动组织没有经过标记的照片。 你可以要求显示所有包含狗的图片，或者是包含雪花的，甚至是像拥抱这样相当抽象的东西。 这些公司都有原型的作品，可以在几秒钟内为照片生成一句描述的话语。

想象一下，为了收集狗的图片，应用程序必须识别从奇瓦瓦州到德国牧羊者的任何东西，如果小狗被倒置或是部分图片是模糊的，也许是在框架或左边的右侧，也许在雾或雪里，抑或有太阳或阴影。 同时它需要排除狼和猫。 单独使用像素来判断怎么可能？

![](2.png)

图像识别的进步远远超出了流行的社交应用程序。 医疗初创公司声称，他们很快将能够比放射科医师更快速、准确地使用电脑阅读X射线，MRI和CT扫描结果，以更早并以更少的侵略性诊断癌症，并加速寻找拯救生命的药物的进程。 更好的图像识别对于自动机器人，无人机以及自动驾驶汽车的改进至关重要，这是一个非常重要的发展，我们在6月份将其作为了封面故事 。 福特，特斯拉，Uber，百度和Google的parent Alphabet都是今天在公路上自动驾驶汽车的原型。

但是大多数人没有意识到的是，所有这些突破在本质上都是一样的突破。 尽管大多数科学家们更倾向于通过原始的学术名称来称呼它们：深层神经网络，但它们都是通过人工智能（AI）技术进行的。

关于神经网络最值得注意的是，没有人将计算机编程，使之用于上述任何特殊用途。 其实没有人可以。 相反，程序员给计算机提供了一种学习算法，让其接受于数十亿个数据-数十万个图像或数年的语音样本-以便对其进行训练，然后让计算机自己弄清楚如何识别所需的对象，单词或句子。

简而言之，这样的电脑现在可以自我学习。 图形处理领导者Nvidia首席执行官黄仁勋表示：“大家本质上是软件编写软件。”  在五年前，Nvidia开始布局于深度学习领域。 （了解更多，请阅读[Fortune对Nvidia CEO黄仁勋的采访](http://fortune.com/2016/03/22/artificial-intelligence-nvidia/) 。）

神经网络并不是一个新的事物。 这个概念可追溯到20世纪50年代，许多关键算法额突破发生在20世纪80年代至90年代期间。 改变的是，今天的计算机科学家终于可以利用强大的计算能力和庞大的数据图像，视频，音频和文本文件在互联网上散布的文件数据库 - 事实证明，这对于神经网络的正常运行至关重要。 Andreessen Horowitz风险投资公司的合伙人Frank Chen说：“这是深度学习的如同寒武纪爆炸一样的事件。”这暗示了这一时期如同大多数高等动物物种大爆发的地质时代。

这一戏剧性的进展引发了一连串的活动。 根据[CB Insights](https://www.cbinsights.com/research/artificial-intelligence-funding-trends-q216/)研究公司的统计，上半年以AI为主的创业公司的股权融资达到了超过10亿美元，创造了历史新高。 该集团表示，2016年第二季度，这些创业公司共有121轮融资，而2011年同期为21个。 在这一领域，总投资额已超过75亿美元，其中自2014年以来的投资总额已超过60亿美元。（9月下旬，五家公司AI领袖 - 亚马逊，Facebook，Google，IBM和Microsoft组建了非营利组织[Partnership on AI](http://fortune.com/2016/09/28/ai-partnership-facebook-google-amazon/)，以提高公众对这一主题的了解，开展对伦理和最佳实践的研究。）

Google在2012年一直在进行两项深度学习的项目。据发言人透露，其所有主要产品领域包括搜索，Android，Gmail，翻译，地图，YouTube和自动驾驶汽车。 IBM的Watson system 仅仅使用了AI，但并不是深度学习，当时它在2011年击败了两个Jeopardy冠军。然而，根据沃森CTO Rob High的说法，沃森的30个组件服务几乎全部通过深度学习得到了扩充。

风险投资者在五年前甚至不知道深度学习，但在今天对于没有深度学习的初创者表示担忧。 陈先生说：“我们现在生活在一个时代，构建复杂的软件应用程序的人们将是必需的。”人们很快就会有这种需求，他说：“ ‘你的软件的语音版本在哪里？’ ‘我怎么跟你的应用程序交谈？ 因为我不想点击菜单。’ ”

观看更多的关于人工智能的视频，请看Fortune的视频
<object id="flashObj" width="480" height="270" classid="clsid:D27CDB6E-AE6D-11cf-96B8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=9,0,47,0"><param name="movie" value="http://c.brightcove.com/services/viewer/federated_f9?isVid=1&isUI=1" /><param name="bgcolor" value="#FFFFFF" /><param name="flashVars" value="videoId=5035430911001&linkBaseURL=http%3A%2F%2Ffor.tn%2F2cWaQC9&playerID=2112050698001&playerKey=AQ~~,AAAB668kGak~,LMlvL4u4ShNOp7KTS6ZmqG8Agt8v7bJW&domain=embed&dynamicStreaming=true" /><param name="base" value="http://admin.brightcove.com" /><param name="seamlesstabbing" value="false" /><param name="allowFullScreen" value="true" /><param name="swLiveConnect" value="true" /><param name="allowScriptAccess" value="always" /><embed src="http://c.brightcove.com/services/viewer/federated_f9?isVid=1&isUI=1" bgcolor="#FFFFFF" flashVars="videoId=5035430911001&linkBaseURL=http%3A%2F%2Ffor.tn%2F2cWaQC9&playerID=2112050698001&playerKey=AQ~~,AAAB668kGak~,LMlvL4u4ShNOp7KTS6ZmqG8Agt8v7bJW&domain=embed&dynamicStreaming=true" base="http://admin.brightcove.com" name="flashObj" width="480" height="270" seamlesstabbing="false" type="application/x-shockwave-flash" allowFullScreen="true" allowScriptAccess="always" swLiveConnect="true" pluginspage="http://www.macromedia.com/shockwave/download/index.cgi?P1_Prod_Version=ShockwaveFlash"></embed></object>

一些公司已经将深度学习融入自己的日常工作中。 Microsoft Research的项目经理Peter Lee说：“我们的销售团队正在使用神经网络来推荐哪些潜在客户可以联系或推荐什么类型的产品。”

硬件世界正在受到颠覆性的影响。 增加的计算能力不仅仅是来自摩尔定律，还来自于二十世纪二十年代后期Nvidia制作的图形处理单元（GPU）的实现 - 这些强大的芯片首先被设计为给玩家丰富的3D视觉体验 - 使得所有这些都比传统的中央处理器（CPU）进行的深度学习计算的效率高出20到50倍。 Nvidia在去年8月份宣布，其数据中心部门的季度收入同比增长了一倍多，达到1.51亿美元。 其首席财务官告诉投资者，“绝大多数增长来自于深度学习。”在83分钟的营收会议中，“深度学习”一词出现了81次。

芯片巨头英特尔公司没有把获得主动权。在过去两个月中，它已经购买了[Nervana Systems（超过4亿美元）](http://fortune.com/2016/08/09/intel-machine-learning-nervana/)和[Movidius（价格未公开）](http://fortune.com/2016/09/06/intel-movidius-vision/) ，两家创业公司为不同阶段的深度学习计算量身打造技术。

谷歌透露，五月份以来的一年里，其一直秘密利用自己的定制芯片（称为张量处理单元）或称为TPU的芯片来运行深度学习的应用程序。 （传感器是数组的数组，如矩阵，通常在深度学习计算中相互叠加。）

事实上，公司可能已经达到另一个拐点。 百度研究首席科学家伍德（Andrew Ng）说：“过去，很多S&P 500强CEO都希望他们在实施互联网战略前早已开始思考。 我认为五年后，会有一些S&P 500强的CEO，希望他们能早点开始思考自己的AI战略。“

在Ng的观点下，即使是互联网的隐喻也不能客观地解释人工智能和深层学习将意味着什么。  “AI是新的电力行业，”他说。 “正如100年前电力行业转型后，AI将会做同样的事情。”

---

认为深度学习是子集的子集。 “人造智能”涵盖了广泛的技术，如传统逻辑和基于规则的系统，使计算机和机器人能够以至少表面上类似思维的方式解决问题。 在这个领域内是一个较小的类别，称为机器学习，这是一个完整的奥秘工具箱的名称，但重要的数学技术使计算机能够在经验执行任务时改进。 最后，在机器学习中，较小的子类称为深度学习。

考虑深度学习的一种方法是“A到B映射”，百度的吴先生说。 “你可以输入音频剪辑并输出脚本。 这是语音识别。“只要你有数据来训练软件，他的可能性是无止境的。 “你可以输入电子邮件，输出可能是：这是否是垃圾邮件？”他说，输入贷款申请，输出可能是客户偿还的可能性。 在车队输入使用模式，输出可以建议下一步发车。

![](3.PNG)

深度学习，在这个愿景中，几乎可以改变任何行业。 领导Google Brain项目的Jeff Dean说：“现在计算机视觉的确有效，现在将发生根本的变化。 或者，他不安地改写自己的句子，“现在电脑已经开了眼睛”。

这是否意味着现在是时候来支持“奇点” - 当超智能机器开始改善自己而不需要人为参与的这一假设时刻，触发了一个失控的循环，让低层人类进一步陷入尘土，造成可怕的后果？

不仅如此。神经网络擅长识别各种不同的模式，有时甚至比我们更好。 但他们不能推理。

---
即将到来的革命的第一缕曙光在2009年初次显现。那年夏天，微软首席研究员Li Deng邀请了多伦多大学的神经网络先驱杰弗里·亨顿来参观。 Li Deng研究组对他的研究印象深刻，实验了用于语音识别的神经网络。 “我们对结果感到震惊，”李先生说。 “与第一批原型相比，我们的精度提高了30％以上。

据李先生称，2011年，微软将深度学习技术引入其商业语音识别产品。 Google于2012年8月起诉讼。

但真正的转折点是2012年10月。在意大利佛罗伦萨的一个研讨会上，斯坦福AI实验室的负责人和着名的年度ImageNet计算机视觉竞赛的创始人费飞飞宣布，两位Hinton的学生发明的软件识别出几乎是第二名竞争对手准确度的两倍。 “这是一个惊人的结果，”Hinton说，“说服了很多以前非常怀疑的人”（去年的比赛中，一个深度学习机器超越了人类的表现）

破解图像识别是发令枪，并开始了各公司的招聘比赛。 谷歌接纳了Hinton和两名赢得比赛的学生。 Facebook注册了法国的深度学习创新者Yann LeCun，他在20世纪80年代和90年代开创了获得ImageNet比赛的算法类型。 百度抢走了前身为斯坦福大学AI实验室负责人的吴先生，他曾于2010年帮助推出并引领着深度学习的Google Brain项目。

自那时起，招聘热潮开始激化。 今天，微软的李先生说，这个空间里有一场“血腥的人才战争”，他表示，顶尖的头脑指令提供了“沿着NFL足球运动员的路线”。

---

68岁的杰弗里·温顿（Geoffrey Hinton）1972年在爱丁堡大学开始教授人工智能研究生课程时，第一次听到神经网络这个概念。 作为学习实验心理学的剑桥本科生，Hinton热衷于神经网络，这些根据脑中的神经元网络结构构建的的软件结构被认为是有效的。 当时，神经网络已经不合时宜了。 他说：“大家以为这一定是是疯了。 但是，Hinton仍然在坚持。

神经网络提供了计算机像儿童那样学习的方式 - 从经验 - 而不是通过由人类定制的程序的繁杂的指示。 他回忆说：“大多数人工智能的灵感来自逻辑，”他回忆说。 “但逻辑是人们在生活中做得很晚的事情。 2岁至3岁的孩子没有过多地用到逻辑。 所以在我看来，神经网络是一个比逻辑智能更好的范例。“（逻辑，因为它发生了，是一个Hinton家族的博弈，他来自一大批知名科学家，是19世纪数学家乔治·布尔（David Boole）的伟大的子孙，在这之后布尔逻辑检索，逻辑和代数被命名。）

在20世纪50年代和60年代，神经网络在计算机科学家中流行起来。 1958年，康奈尔研究心理学家弗兰克·罗森布拉特（Frank Rosenblatt）在海军支持的项目中，在水牛城的一个实验室里建造了一个原型神经网络，并称之为“感知器”。 它使用一个填满整个房间的穿孔卡片电脑。 经过50次试验，它学会区分有左边标记的卡片和右边有标记的卡片。 “纽约时报 ” 报道 ，“海军今天透露了一台电子计算机的原型，期望它能够走路，谈话，看，写，重建自我并能意识自己的存在。”

感知器，其软件只有一层神经元样节点，这被证明是有局限性的。 但研究人员认为，可以通过多层或深层神经网络实现更多的功能。

Hinton以这种方式解释了基本思想。 假设神经网络正在解读其中
一些包含鸟类的摄影图像。 “所以输入将会进入像素，然后第一层单位会检测到一些边缘。 他说，下一个级别的神经元，分析从第一层发送的数据，将学习检测“像角落的东西，两个边缘以一定角度交汇”。 其中一个神经元可能会对鸟的喙的角度产生明显的响应。

下一个级别的神经元“可能会发现更复杂的配置，像一堆边缘排列在一个圆圈中。”这个级别的神经元可能会响应鸟的头部。 在更高的水平上，神经元可以检测头部附近的喙状角度的重复并置。 “这是一个很好的提示，它可能是一只鸟的头，”Hinton说。 每个更高层的神经元对更复杂和抽象的概念作出反应，直到最顶层的概念对应于我们的“鸟”概念。

然而，要学习，深层神经网络需要做的不仅仅是以这种方式通过层发送消息。 它还需要一种方法来查看它是否在顶层获得正确的结果，如果不是，则将消息发送回来，以便所有较低的神经元样单元可以重新调整其活动以改善结果。 这就是学习如何发生的。

## 深度学习发展历史的关键时刻

![](x1.PNG)

![](x2.PNG)

![](x3.PNG)

![](x4.PNG)

![](x5.PNG)

在20世纪80年代初，Hinton正在研究这个问题。 法国的研究员，也是刚刚在巴黎开始他的研究生学习的Yann LeCun，在1983年的一篇关于多层神经网络的Hinton发表的论文中偶然发现。 “这不是用一些术语来制定的，”LeCun回忆道，“因为当时提到‘神经元’或‘神经网络’这个词时，实际上很难发表论文。 所以他以一种模糊的方式写了这篇文章，以便它能通过审稿人的查验。 但是我认为这篇论文是非常有趣的。“两年后，两人相遇，并走到了一起，开始研究。

1986年，Hinton和两位同事撰写了一篇关于纠错问题的一种算法解决方案的一篇创新型论文。 “他的论文基本上是第二波神经网络浪潮的基础，”LeCun说。 它重燃了人们对该领域的兴趣。

在与Hinton合作后，LeCun于1988年搬到了AT＆T的贝尔实验室，在接下来的十年里，他做的基础工作，目前仍被用于大多数图像识别任务。 在20世纪90年代， NCR ，然后是贝尔实验室子公司，根据LeCun的研究成果，商业化了银行广泛使用的神经网络系统，可以读取手写的数字。 同时，两名德国研究人员 - 现在在林茨大学的Sepp Hochreiter和卢加诺瑞士AI实验室的总监JürgenSchmidhuber都独立开创了一种不同类型的算法，20年后，这个算法在自然语言处理方面变得至关重要。

尽管如此，在20世纪90年代中期，神经网络再次陷入了不安，受限于当时的算力，更为有效的机器学习工具被削弱了。 这种情况持续了近十年，直到计算能力增加了三到四个数量级，并且研究人员发现了GPU加速。
但是还有一件事：数据。 虽然互联网充斥着，大多数数据 - 特别是当它是图像时 - 没有标记，但是那是你需要训练神经网络的材料。 这就是斯坦福大学AI教授Fei-Fei Li，他介绍说：“我们的愿景用大数据来改变机器学习的运作方式。” “数据驱动学习”。

2007年，她推出了ImageNet，构建了一个免费的拥有1400多万个经过标记的图像的数据库。 它于2009年开始运营，第二年她设立了一个年度竞赛，以激励和推广计算机视觉处理的突破。

2012年10月，当有两个Hinton的学生赢得了这场比赛时，深度学习的时代已经拨云见日。

在那时，公众也听说过深度学习，虽然是通过不同的渠道了解的。 2012年6月，Google Brain公布了一个前瞻性的项目的结果，这个项目现在俗称为“ cat experiment(猫实验)”，它引起了人们的共鸣，并在社交网络上广为流传。

该项目实际上探索了一个重要的未解决的深度学习问题，称为“无监督学习”。今天，几乎所有商业用途的深度学习产品都使用“受监督的学习”，这意味着神经网络用标记过的数据进行训练（如ImageNet）。 与“无监督学习”相反，神经网络显示出未标记的数据，并且仅仅被要求寻找重复出现的模式。 研究人员希望有一天能够掌握无人监督的学习，因为这样机器可以从今天无法使用的庞大的数据库中发现世界，像婴儿那样，完全凭借自己的能力去感受这个世界。

在猫实验中，研究人员在1000台计算机上将巨大的神经网络暴露于1000万个未标记的图像中，这些图像都是从YouTube视频中随机抽取的，然后让软件做它们该做的事情。经过了一段时间的运算，结果变得清晰时，他们检查了最高层的神经元，发现，其中一个神经元对猫的图像进行了有力的响应。 “我们还发现一个神经元对人的面孔有很大的反应，”在Google Brain领导这个项目的Ng说道。

然而结果也令人费解。 “我们没有发现一个对汽车产生强烈反应的神经元，”例如，“有很多我们不能分配一个英文单词神经元。 所以这是十分困难的事情。”

实验创造了一种感觉能力。 但无人监督的学习仍然没有实现 - 这是未来科学家们要继续为之奋斗的事情。

---

毫不奇怪，迄今为止已经商业化部署的大多数深度学习的应用程序，所涉及的像Google，微软，Facebook，百度和亚马逊这样的公司，它们都拥有深度学习计算所需的大量数据。 许多公司正在努力开发更实际和有用的“聊天室” - 自动客户服务代表。

> ### 四大科技巨头在深度学习领域投入大量资源
>    *  **谷歌**
>``深度学习的Google Brain项目，于2012年年中将神经网络引入其语音识别产品，并于2013年3月留住了神经网络的先驱Geoffrey Hinton。现在有1000多个深度学习的项目正在进行中，例如扩展搜索，Android，Gmail，照片，地图，翻译，YouTube和自动驾驶汽车。在2014年，它收购了DeepMind，其强化的深度学习项目AlphaGo在3月份击败了世界冠军Lee Sedol，树立了一座人工智能的里程碑。``
>
>    *   **微软**
>
>   ``微软在2011年上半年向其商业语音识别产品加入了深度学习，包括Bing语音搜索和X-Box语音命令。该公司现在使用神经网络进行搜索排名，图片搜索，翻译系统等。“很难完整地叙述这个技术的普遍影响，”李先生说。去年，它赢得了重要的图像识别比赛，9月份，其语音识别基准所记录的的创纪录的低错误率为6.3％。``
>
>    *   **FACEBOOK**
>
>   ``2013年12月，Facebook聘请法国神经网络创新者Yann LeCun指导其新的AI研究实验室。Facebook调用超过40种的语言每天翻译约20亿个用户的帖子，并表示每天有8亿用户看到它的翻译。（大约有一半的讨论组不会说英语。）Facebook还使用神经网络进行照片搜索和照片组织，并且正在开发一个可以为视障者使用的，可以为未标记照片生成语音字幕的功能。``
>
>    *   **百度**
>
>   ``2014年5月，百度聘请了早前帮助推出和领导Google Brain项目的Andrew Ng领导其研究实验室。中国领先的搜索和网络服务网站百度使用神经网络进行语音识别，翻译，照片搜索和自动驾驶汽车项目等。语音识别在中国非常重要，中国是一个移动优先的社会，其主要语言是很难输入设备的普通话。百度说，在过去18个月内，通过言语交流的客户数量翻了三番。``
>


像[IBM](http://fortune.com/fortune500/ibm/)和微软这样的公司也在帮助企业客户适应深度学习的应用程序，如语音识别接口和翻译服务 - 对于企业自己来说，同时像Amazon Web Services这样的云服务则为那些想要开发自己的软件的客户提供便宜的GPU驱动的深度学习计算服务。 丰富的开源软件，如Caffe，Google的TensorFlow，以及亚马逊的DSSTNE，已经开创了创新过程，并拥有开放的发表准则，许多研究人员将其结果立即发布在一个数据库中，而无需等待同行评审。

许多最令人激动的新尝试是应用在医疗领域深度学习所带来的（见侧栏）。 我们已经知道，神经网络对于图像识别工作效果很好，斯坦福大学教授安德森·霍洛维茨（Andreessen Horowitz）生物投资部门负责人维杰·潘德（Vijay Pande）评论到，“医生所做的很多工作都是图像识别，无论我们在谈论的是放射学，皮肤科，眼科，或许多其他“科学”。 ”   

![](4.PNG)    

虽然放射科医生在职业生涯中可能会审阅数千张图像，但电脑可以在很短的时间内接受数以百万计的图像。 Pande表示：“我们很自然地能认识到这个图像问题能够更好地被计算机解决，正是因为它们能够比人类整合更多的数据。”

深度学习潜在的优势不仅在于准确性更高，分析速度更快，而且服务更加规范。 随着这种技术的标准化，每个患者都将从中受益。

深度学习的最大影响可能会被认为是将其整合到其他的人们尚未想到的人工智能技术的整个工具箱中。 例如，Google的[DeepMind](https://deepmind.com/)已经被科学家通过将深度学习与一种称为强化学习的相关技术结合起来去实现令人吃惊的事情。 使用这两种技术，科学家创造了AlphaGo。这套人工智能系统，在不久前的三月时，击败了中国围棋这个古老游戏的冠军选手，被广泛地被人们认为是一个里程碑式的AI成就。 和IBM的Deep Blue在1997年击败了国际象棋冠军Garry Kasparov不同是，AlphaGo没有被编程为决策树，或者是如何评估事物重要性的方程式，抑或是用if-then规则编写的程序。 DeepMind公司首席执行官Demis Hassabis表示：“AlphaGo学会了如何通过自我对弈以及观察大型专业比赛来从本质上学会如何进行决策。 （在训练期间，阿尔法Go进行了百万次的自我对弈游戏。）

游戏可能看起来像一个人造环境。 但是Hassabis认为相同的技术还可以应用于现实世界的情景中。 事实上，Google在7月份报道说，通过采用与AlphaGo类似的方法，DeepMind能够将Google数据中心的能源利用效率提高15％。 “在数据中心，可能有120个不同的变量，”Hassabis说道。 “你可以改变风扇的状态，打开窗户，改变计算机系统，改变电力的去向。 你可以从传感器，比如温度温度传感器，以及所有的传感器得到数据。 就像棋类对弈， 通过不断的试错，你将了解到正确的操作是什么。

“所以说这是很棒的一件事情，”他继续说。 “你每年可以节省数千万美元，并且它对环境也起到了一定的保护作用。 数据中心在世界各地使用大量的电力。 我们现在希望更大规模地，甚至是在国家电网级别来推广它。”

聊天机器人都很不错。不过这只是一个很酷的应用程序。

*这篇文章的一个版本出现在2016年10月1日的“财富”杂志上，标题为“深度学习革命”。该版本包含了CB Insights研究公司的更新数据.*

                                                                                         译于2017年10月
